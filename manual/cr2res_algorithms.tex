\section{Algorithms}
\label{sec:algorithms}

% \red{\textit{The first part contains the detailed discussion and the
%     mathematical description of the used algorithms. The second part contains
%     the recipe algorithm, i.e. a high-level description of the recipe
%     flow-chart and how it changes for different parameter settings.}}

\subsection{General Algorithms}
\label{sec:algorithms-general}

\subsubsection{Optimal Extraction}
\label{sec:extract}
\begin{figure}[ht]
    \begin{center}
\includegraphics[width=0.45\linewidth]{rectification.pdf}
\includegraphics[width=0.45\linewidth]{swath_weights.pdf}
\end{center}
\caption{\it Left: Illustration of swath rectification. Right: The weights 
    for combining the spectra from overlapping swaths.}
\label{fig:swaths}
\end{figure}

\begin{figure}[ht]
    \begin{center}
\includegraphics[width=0.85\linewidth]{extr_model.png}
\end{center}
\caption{An example of the optimal extraction. \emph{Top:} The flat-fielded,
combined, and pair-wise subtracted frame, with the BPM applied and zoomed-in to
part of a single spectral order. \emph{Panel 2:} The model of the same region,
reconstructed from the extracted spectrum and slit-function. \emph{Panel 3:} The
difference between the two above, showing the residuals. \emph{Bottom:} The
extracted spectrum itself, on the same x-axis as the panels above.}
\label{fig:extrmodel}
\end{figure}

The optimal extraction along the tilted and curved slit is a centerpiece of the
\instrument\ DRS and several recipes make use of it. Full details and
mathematical description can be found in \cite{2021A&A...646A..32P}. Here, we
simply summarize the most important practical implications from a user
perspective.

To extract a spectral order from a calibrated 2D frame into a 1D spectrum, using
a \emph{trace} from the TW table, the following steps are carried out:
\begin{itemize}
    \item Calculate the extraction height from the edge-polynomials, if not
    explicitly given via \texttt{-{}-extract\_height}.
    \item Cut out a rectangular region around the mid-line, called a
    \emph{swath} from the frame, using the height and the value of
    \texttt{-{}-extract\_swath\_width}.
    \item Rectify the swath by shifting columns by integer values such that the
    mid-line only retains values between $0\ldots 1$, like illustrated in
    \figref{fig:swaths} (left).
    \item Iteratively approximate the swath surface by two vectors: the spectrum
    along the mid-line and the slit-function along the slit projection, taking
    its changing tilt into account. The slit function is oversampled by a factor
    \verb!--extract_oversample!.
    \item Step by a half swath-width to the next one, and repeat. This way
    swaths overlap fully and the order effectively gets extracted twice.
    \item Once all swaths are extracted, the spectra from each are merged into
    one, with linearly in-/decreasing weights, as in \figref{fig:swaths}
    (right).
    \item The spectrum and slit-functions are saved, and used to reconstruct a
    2D model of the frame, saved separately.
    \item The errors are estimated from the residual between data and model.
\end{itemize}

A major advantage of this extraction algorithm is that it makes no assumption
about the slit-function, except that it does not change within a swath. This
allows, for example, to combine jittered nodding frames into one, and extract it
together.

In addition, the model by design cannot approximate features that are not
present in all pixels that contribute to a certain bin in the spectrum or the
slit-function. This makes spectra robust towards e.g.~cosmic rays.

Fig.~\ref{fig:varyovers} shows the effect of the \emph{slit-function
oversampling}, that can be changed via  the parameter \linebreak
\verb!--extract_oversample!. As mentioned before, this factor linearly affects
the computation time. The amount of oversampling necessary depends on how
quickly the mid-line of a spectral order changes with respect to detector rows,
and how sharply the slit-function changes. The default value of $5$ is enough in
many situations, but clearly leaves artifacts in the example shown, which was
chosen to be close to worst-case, and requires an oversampling $>12$ for optimal
results.

\putgraph{.8\linewidth}{varyoversample.pdf}{varyovers}{Example spectrum,
 extracted with varying oversampling, and vertically offset for plotting.
 In this case, oversampling of $12$ is needed to no longer see "spiky" artifacts.}

There are a few more parameters that influence the extraction:
\begin{itemize}
    \item \verb!--extract_swath_width! sets the width of the swath, in pixels,
    i.e.~how large a piece of a spectral order should be processed at a time.
    Meaningful values range from $~50$ (high S/N necessary) to the full detector
    width. The default is $800$ and works in most cases, because the
    slit-illumination rarely varies on that scale.
    \item \verb!--extract_height! sets the height in pixels of the extracted
    region, symmetrical around the mid-line of the trace. By default, this is
    not set and the upper and lower edge polynomials of the trace are used to
    set the height. Setting this parameter therefore overrides the role of the edge polynomials in the extraction. In other words, this parameter takes precedence over the slit-fraction when it comes to
    specifying the extraction height.
    \item \verb!--extract_smooth_slit! is a regularization parameter for the
    slit-illumination vector, as it is approximated during the extraction. The
    value is roughly the size of the smoothing kernel in pixels, and should not
    be set below $1.0$ to avoid ringing. Default is $2.0$.
    \item \verb!--extract_smooth_spec! is analogous to the previous, but along
    the spectrum instead. It defaults to $0.0$ to not degrade resolution, but
    can be increased as needed.
\end{itemize}

For the utility recipe \verb!cr2res_util_extract! these parameters are named
without the prefix \verb!extract_!.

\subsubsection{Other extraction methods}
\label{sec:otherextr}

\verb!cr2res_util_extract! has another feature up its sleeve: the parameter
\verb!--method! which allows using different algorithms to extract spectra from
the 2D frame. It can take the following values.
\begin{itemize}
    \item \verb!SUM!, a simple vertical sum of the spectral order. Because of
    the non-vertical slit, spectral features will be broadened.
    \item \verb!MEDIAN!, same as previous, but calculating the median instead of
    the sum. The value is multiplied by the extraction height, so that the
    normalization is the same as the other methods.
    \item \verb!TILTSUM! is like \verb!SUM!, but first shifts the detector rows
    according to the slit tilt. Only integer shifts, so there is still smoothing
    from sub-pixel tilt.
    \item \verb!OPT_VERT! should not be used! It runs the optimal extraction
    along a vertical slit, but is not optimized for speed and therefore slower
    than
    \item \verb!OPT_CURV!, the default optimal extraction, as described above.
\end{itemize}

For all other recipes, \verb!OPT_CURV! is the only choice.

\subsubsection{Errors and Signal-to-Noise}
\label{sec:errors}

Raw frames contain pixel values in ADU. All data products are in ADU also,
i.e.~no conversion to electrons is made, and no normalization to $1s$-exposure by
dividing by \verb!DIT!. There are however several steps along the way to the
final spectra that affect the absolute values of pixels and spectral bins, which
is why it makes sense to summarize them here.

Some things to keep in mind about ADU values
\begin{itemize}
    \item For data with \verb!NDIT >1!, each sub-exposure gets averaged in the
    detector software.
    \item In a nodding sequence the pair-wise subtracted frames are also
    averaged.
    \item The normalization of the output-spectra is like that of a sum of pixel
    values, collapsed along the slit, i.e. summed-up ADU.
\end{itemize}


Errors, both in maps and spectra are absolute. Calibrations are applied to raw
frames in the following order, at each step propagating the error into the
output
\begin{itemize}
    \item Bad pixel map\footnote{BPMs have no errors, therefore no
    error-propagation at this step.}
    \item Detector non-linearity.
    \item Shot-noise gets added to each pixel's error, based on $\sqrt{\verb!ADU!}$
    divided by $\sqrt{\verb!NDIT!}$ and $\sqrt{\verb!GAIN!}$.
    \item Dark-subtraction. The master darks are DETLIN-corrected, because they
    are not "dark" but contain thermal emission.
    \item Optional subtraction of all detector rows with a row, that is derived
    by taking the vertical median over the 40 bottom rows which receive no
    light.
    \item Division by the normalized flat-field.
    \item Optional correction for cosmic rays (usually not necessary).
\end{itemize}


The errors of each pixel are used in the optimal extraction, and once that is
done, a \emph{model} gets reconstructed from the spectrum and the slit-function.
The residual between data and model gets quadratically added to the pixel
uncertainties, which in turn get divided by the slit function to become the
error of the spectral bin.

This means that the spectrum can be directly divided by the error-spectrum to
obtain the signal-to-noise ratio (S/N). No further conversions are necessary.

However, in order to compare this S/N with the theoretical expectation from
Poissonian statistics, users will have to scale the ADU-values of the spectrum
by the gain and the number of averaged frames (NDIT or combined frames), before
taking the square-root (Eq.~\ref{eq:snr}). In general, the measured S/N after
extraction is somewhat lower than the theoretical value.

\begin{equation}
    \label{eq:snr}
    S/N = \sqrt{(ADU_A+ADU_B)*NDIT*NEXP*NABCYCLES*GAIN}\quad ,
\end{equation}
where $ADU_{A,B}$ are the spectra from nodding positions A and B, respectively.
For other types of observations replace accordingly. Polarimetric observations
always take four exposures at different SPU-angles; the demodulated intensity
spectrum (Stokes I) therefore needs an additional factor 4 in the equation.

Note that an important factor in getting high S/N in spectra is to apply deep
enough flat-fields, that ideally exceed the S/N in the observations. And that
the detector linearity correction can be a limiting factor, see below.

\subsection{Recipes Algorithms} 
\label{sec:algorithms-recipes}

\subsubsection{Order Tracing}
\label{sec:ordertrace}

As written above, by a \emph{trace}, we mean a polynomial, in pixel-coordinates
of a single detector, that follows the mid-line of a spectral order. And two
more polynomials for the upper and lower edges of the slit projection, as shown
in Fig.~\ref{fig:flat_trace}.

The way this is derived is by first determining which pixels in a FLAT frame
contain signal, and which don't. To that end the image is smoothed first
horizontally, then vertically, and then compared to the un-smoothed frame via
thresholding. The recipe option \verb!trace_opening!, true by default, joins
together closely adjacent clusters of pixels.

After that it is determined which spectral order the pixels belong to. For this
purpose, the mean Y-coordinate for each order is present in the raw file
headers.

Lastly, the X and Y-coordinates for pixels within the same order are fitted with
a polynomial, which gives the mid-line of the trace. In addition, edge-detection
gives the upper and lower edges of the spectral order.

\subsubsection{Measuring the slit-shape}
\label{sec:tilt}

The recipe \verb!cr2res_util_slit_curv! takes as input a TW, for the order
traces, and an FPET frame. The algorithm finds the etalon peaks, which give good
coverage in each spectral order. It then fits the shape of each peak with a
polynomial P(y), because in principle a curved slit could cross the same
x-coordinate more than once.

The coefficients of these polynomials are then fitted with a P(x) for each
degree. This ensures a smooth change of the slit tilt with wavelength, removes
outliers, and allows to store the information in the TW in an analogous way to
the polynomials for trace and wavelength solution. The TW-columns are named
\verb!SlitPolyA!, \verb!SlitPolyB! and \verb!SlitPolyC!.

As of DRS version 1.2.4 (Feb 2023), two changes are introduced to the way the
slit tilt and curvature are handled:

\begin{enumerate}
    \item The slit shape is no longer \emph{static}, in the sense that the
    reductions using the \verb!cr2res_cal_*! recipes or the Reflex workflow not
    longer rely on the values in the static TW-files. Instead the recipe
    \verb!cr2res_cal_wave! now starts by measuring the slit shape and saves the
    result together with the wavelength calibration in the output TW. This
    change is because the slit tilt has unexpectedly been found to change after
    a warm-up cycle.
    \item The choice between a straight slit or a parabolic curve is no longer
    hardcoded but offered as the parameter \verb!--degree! or
    \verb!--slit_degree! on recipes \verb!cr2res_util_slit_curv! and
    \verb!cr2res_cal_wave!, respectively. The default has been changed to second
    degree, i.e.~a parabolic slit, which has been found to give slightly better
    residuals after extraction, even though the slit is much more tilted than
    curved.
\end{enumerate}

\subsubsection{Wavelength calibration}

There are several ways to calibrate the wavelength scale, and each corresponds
to one of the values that the parameter \texttt{-{}-wl\_method} of
\texttt{cr2res\_util\_wave} can take.

With \texttt{-{}-wl\_method=XCORR} the input catalog of lines is converted
into a synthetic spectrum that is cross-correlated with the extracted lamp
spectrum. The first-guess solution is varied within the rage allowed by the parameters \verb!--wl_degree! and \verb!--wl_err!, also taking a \verb!--wl_shift! into account, if given. The result with the best cross-correlation outcome is kept as result.
Each detector-order is calibrated separately.

The special case of \verb!--degree=0! means a shift of the zero-point only, without changing the dispersion or the higher orders of the input solution. Therefore \verb!--keep=TRUE! is needed, which does exactly that. Without it, the output solution always has the degree that is asked for via \verb!--degree!, and there cannot be a $0$th-degree solution.

By the way, the option \verb!--fallback!, when TRUE, also allows you to propagate an input solution into the output, but under a different condition. Namely when the calibration of a detector-order fails.

The calibration spectra that are used for the cross-correlation are from an
Uranium-Neon lamp (UNE). The catalogs for U-lines come from
\cite{2018A&A...618A.118S} and \cite{2011ApJS..195...24R}. They are used for YJ
and HK-bands, respectively. Note that all wavelengths are vacuum, not air.

There are two other methods, not used by default, that can be applied to the UNE
lamp data, \verb!LINE1D! and \verb!LINE2D!. Instead of cross-correlating a
synthetic spectrum, these go through the list of catalog lines and try to fit
each with a Gaussian. The line-centers found this way are then fit against the
catalog wavelength to arrive at the solution. This method is naturally more
sensitive to blended lines and depends on the catalog line being the strongest
peak in the spectrum cut-out that is fitted, which in turn is determined by the
input solution and \verb!--wl_err!. The catalogs with lines for each setting
that are distributed with the DRS are selected with the XCORR in mind, because
in some spectral regions lines are sparse enough that weak lines have to be
used. Therefore it is likely necessary to make a further, or altogether
different selection of lines to get reliable results with line-fitting.

The difference between \verb!LINE1D! and \verb!LINE2D! is that the former treats
each detector-order independently, like \verb!XCORR!, while the latter makes use
of the grating equation that connects the solution between orders. The absolute
order number becomes the Y-coordinate of the 2D-polynomial and the parameter
\verb!--xdegree!\footnote{The \texttt{x} in the name stands for
"cross-dispersion", not the X-coordinate.} sets the degree in this direction.



%%%%%%%% UNE above, FPET below
\putgraph{\linewidth}{wavecal_resids_H1567.png}{waveresids}{A representative example of residual values after wavelength calibration with the FPET. Each dot indicates the difference between expectation and reality, for the final wavelength solution that was found. Axes in several units are included.}

The method used for calibrating with the spectra from the FPET is
\verb!--wl_method=ETALON! and it is heavily inspired by
[RD05]\cite{2019A&A...624A.122C}. It makes use of the intrinsic regularity of
the FPET peaks, and applies a 2D-fit to the spectra from each detector. More
details in a future iteration of this document.


% UNE + FPET below
In contrast to \verb!cr2res_util_wave! which executes a single wavecal-method on
pre-processed data, the recipe \texttt{cr2res\_cal\_wave} works on raw wavecal
inputs and executes several calibration steps after one another, using both UNE
and FPET as taken together by the wavecal template. (If only one or the other is supplied, then naturally only the appropriate method is executed.)

The calibration strategy could, if one were inclined to do so, be replicated
with individual calls of util-recipes, like this:

\begin{itemize}
    \item apply master calibrations to raw (UNE and FPET) frames, with \verb!cr2res_util_calib!
    \item extract spectra from the calibrated frames, \verb!cr2res_util_extract!
    \item calibrate the UNE spectra with \verb!--wl_method=XCORR!, \verb!degree=0! and \verb!--keep!, which means a shift of the zero-point.  \verb!cr2res_util_wave!
    \item calibrate the extracted FPET spectra, using the solution from the previous step as starting point.\linebreak\verb!cr2res_util_wave! \verb!--wl_method=ETALON! \verb!--degree=4! \verb!--xdegree=6!
\end{itemize}

This two-step strategy has been found to give reliable results in all instrument
settings in Y-K bands. An example of final residuals is shown in
Fig.~\ref{fig:waveresids}.

% LM below
As noted in \ref{sec:knownissues}, there is no active wavelength-calibration for
the L and M-bands, since neither the UNE or the FPET are usable there. The use
of gas-cells is being investigated, but in the meantime, using \verb!molecfit!
has been found to give good results, see App.~\ref{sec:molecfit}.

Also note that the TW tables that are delivered with the DRS static calibrations
already have wavelength solutions derived this way, and should therefore be
readily usable for observations taken with metrology.


\subsubsection{Background Subtraction}
\label{sec:backgr}

In general, the best way to subtract background  --  be it originating from the
sky, telescope, instrument or detector  --  is to use nodding in observations.
As explained above, the recipes take care of the frame subtraction and
combination.

There are two more ways to subtract background which can be activated with the
following parameters of the appropriate recipes.

The bottom $~40pix$ rows of the detectors are physically blocked from receiving
light. When \linebreak\verb!--subtract_nolight_rows=TRUE! then the DRS will take a
vertical median over these rows, and then subtract the result from all detector
rows.

With \verb!--subtract_interorder_column=TRUE! given, recipes will fit a
low-order polynomial to the pixel values between the spectral
orders\footnote{The master-flat is used to determine these pixels, because at
this stage of the frame calibration the DRS does not have access to a TW table.
Therefore this method requires a flat-field to be present in calibration
inputs.}, and then subtract the result. This is done for each column
independently which allows it to address both scattered light and mitigate the
occasional detector artifacts that randomly affect a certain vertical read-out
channel.

The latter method has given good results in tests and is therefore turned on by
default. We cannot however completely exclude the possibility of negative
side-effects in certain situations.

\subsubsection{Detector non-linearity}
\label{sec:detlin}

\putgraph{.8\linewidth}{detlin_1133_1564.png}{detlincorr}{Before and after
 non-linearity correction for a randomly picked pixel in each detector. Red
 circles: Raw ADU/s vs.~ADU. Green dots with errorbars: ADU/s as read from FLATs
 to which the previously derived calibration has been applied, using
 \texttt{cr2res\_util\_calib}. The closer to horizontal the points fall, the
 better the correction, because the actual illumination is kept constant. The
 standard-deviation from 1 is given in the title. Diamonds and shaded region: As
 a cross-check, the plotting-script separately reads and applies the correction
 to the raw values; should align with green dots and errors.}


Users are provided (via the ESO Archive\footnote{As of writing (2022-02-22),
this reduced calibration is not yet in the Archive, but should become available
in the coming weeks. If 20GB of download and disk space are not an issue, then
feel free to search for the raw data via
\texttt{TPL.ID=CRIRES\_spec\_tec\_DetLinMon} and run the recipe yourself.}) with the
calibration data-product (\verb!PRO.CATG=CAL_DETLIN_COEFFS!) that is needed to
apply the correction for the non-linear response of detector pixels. This file
contains for each pixel the coefficients of a polynomial which, when evaluated
at a certain ADU-level, yields the correction factor by which to multiply the
raw ADU, so that the value becomes that which a linear response would have
given.

The \verb!cr2res_obs_*! recipes take this file as optional input and apply the
correction, as do some calibration recipes. Keep in mind however that the
$0.5\%$ error of each pixel's correction effectively \textbf{limits the S/N} of
the resulting spectra. The detlin should \emph{not} be applied to the flat-field
because doing so introduces the noise a second time. Methods to reduce the
detlin noise are being investigated.


In order to derive this correction, a long series of exposures with the
flat-field lamp are taken by the aforementioned template, with increasing DITs,
starting from very short until well into saturation. This is repeated for
several spectrograph settings in order to cover the gaps between the spectral
orders. A series of DARKs with matching DIT is also obtained and subtracted from
the FLATS, because the non-zero detector background pattern at short DITs would
otherwise influence the determination of the linear response.

The reduction of the data set is done by \verb!cr2res_cal_detlin!
\begin{shell}[fontsize=\footnotesize]
    %prompt cat detlin.sof
    CRIRE.2021-10-18T09:50:30.827.fits DETLIN_LAMP
    CRIRE.2021-10-18T09:50:32.845.fits DETLIN_LAMP
    ...
    CRIRE.2021-10-18T09:59:12:345.fits DETLIN_DARK
    ...

    %prompt esorex cr2res_cal_detlin detlin.sof
\end{shell}

For each pixel, the recipe carries out the following steps on the sequence of images:
\begin{itemize}
    \item Convert ADU to ADU/s by dividing by DIT. Plotting ADU/s versus ADU
    gives a horizontal line in the linear regime (illuminating flux is kept
    constant), and deviates downward for larger ADU (Fig.~\ref{fig:detlincorr}).
    \item Assume linear response up to 4000 ADU and take median of all
    measurements below this threshold to find the \emph{true ADU/s}.
    \item Divide the non-linear ADU/s by the true value to get the correction
    factors, depending on ADU-level.
    \item Fit a parabola to the correction factors' dependence on ADU.
    \item Save the coefficients into data product.
\end{itemize}

This procedure is repeated for the other spectrograph settings and in the end
the coefficients are merged, with weights according to their errors.


\putgraph{.8\linewidth}{detlin_corrfacs.png}{detlincorrfac}{The size of the
non-linearity correction, depending on raw ADU-level.}


\putgraph{.8\linewidth}{detlin_errmaps.png}{detlinerrmap}{Error maps for three
ADU levels. These are the propagated errors of the correction factor for each
pixel, at that ADU. Clearly visible are the spectral orders and gaps, with the
largest errors for the pixels that are only illuminated by one of the three
spectrograph settings.}


\putgraph{.8\linewidth}{detlin_accur.png}{detlinaccur}{How well does a known
constant illumination get recovered by applying the correction? This is what the
deviation from the horizontal line at 1.0 in this figure shows. A value of 1.005
on the y-axis corresponds to 0.5\% inaccuracy. Points are average deviations of
random pixels for a certain ADU-bin; errorbars here are the standard-deviation
of values in the same bin, not the propagated errors.}

The additional figures \ref{fig:detlinerrmap}, \ref{fig:detlincorrfac} and \ref{fig:detlinaccur} show some statistics of the outcome.
For example, one way to read these figures is that at 30,000 ADU, a correction
of around 10\% needs to be applied, and this correction is accurate to around
0.5\%. 
